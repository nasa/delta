<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>delta.extensions.metrics API documentation</title>
<meta name="description" content="Various helpful loss functions." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>delta.extensions.metrics</code></h1>
</header>
<section id="section-intro">
<p>Various helpful loss functions.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># Copyright © 2020, United States Government, as represented by the
# Administrator of the National Aeronautics and Space Administration.
# All rights reserved.
#
# The DELTA (Deep Earth Learning, Tools, and Analysis) platform is
# licensed under the Apache License, Version 2.0 (the &#34;License&#34;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#        http://www.apache.org/licenses/LICENSE-2.0.
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &#34;AS IS&#34; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# pylint: disable=too-many-ancestors
&#34;&#34;&#34;
Various helpful loss functions.
&#34;&#34;&#34;

import tensorflow as tf
import tensorflow.keras.metrics #pylint: disable=no-name-in-module

from delta.config import config
from delta.config.extensions import register_metric

class SparseMetric(tensorflow.keras.metrics.Metric): # pylint:disable=abstract-method # pragma: no cover
    &#34;&#34;&#34;
    An abstract class for metrics applied to integer class labels,
    with networks that output one-hot encoding.
    &#34;&#34;&#34;
    def __init__(self, label=None, class_id: int=None, name: str=None, binary: int=False, label_id: int=None, **kwargs):
        &#34;&#34;&#34;
        Parameters
        ----------
        label
            A class identifier accepted by `delta.imagery.imagery_config.ClassesConfig.class_id`.
            Compared to valuse in the label image.
        class_id: Optional[int]
            For multi-class one-hot outputs, used if the output class ID is different than the
            one in the label image.
        label_id: Optional[int]
            Internal use only, for reconstructing this class from a .savedmodel format
        name: str
            Metric name.
        binary: bool
            Use binary threshold (0.5) (one input, two classes) or argmax on one-hot encoding (one input per class).
        &#34;&#34;&#34;
        super().__init__(name=name, **kwargs)
        self._binary = binary
        self._label_id = config.dataset.classes.class_id(label) if label_id is None else label_id
        self._class_id = class_id if class_id is not None else self._label_id

    def reset_state(self):
        for s in self.variables:
            s.assign(tf.zeros(shape=s.shape))

    def get_config(self):
        cfg = super().get_config()
        cfg.update({&#39;binary&#39;: self._binary, &#39;class_id&#39;: self._class_id, &#39;label_id&#39;: self._label_id})
        return cfg

class SparseRecall(SparseMetric): # pragma: no cover
    &#34;&#34;&#34;
    Recall.
    &#34;&#34;&#34;
    def __init__(self, label=None, class_id: int=None, name: str=None, binary: int=False, **kwargs):

        super().__init__(label, class_id, name, binary, **kwargs)
        self._total_class = self.add_weight(&#39;total_class&#39;, initializer=&#39;zeros&#39;)
        self._true_positives = self.add_weight(&#39;true_positives&#39;, initializer=&#39;zeros&#39;)

    # sample_weight is unused but required by tensorflow
    def update_state(self, y_true, y_pred, sample_weight=None): #pylint: disable=unused-argument, arguments-differ
        y_true = tf.squeeze(y_true)
        right_class = tf.math.equal(y_true, self._label_id)
        if self._binary:
            y_pred = y_pred &gt;= 0.5
            right_class_pred = tf.squeeze(y_pred)
        else:
            y_pred = tf.math.argmax(y_pred, axis=-1)
            right_class_pred = tf.math.equal(y_pred, self._class_id)
        total_class = tf.math.reduce_sum(tf.cast(right_class, tf.float32))
        self._total_class.assign_add(total_class)
        true_positives = tf.math.logical_and(right_class, right_class_pred)
        true_positives = tf.math.reduce_sum(tf.cast(true_positives, tf.float32))
        self._true_positives.assign_add(true_positives)

    def result(self):
        return tf.math.divide_no_nan(self._true_positives, self._total_class)

class SparsePrecision(SparseMetric): # pragma: no cover
    &#34;&#34;&#34;
    Precision.
    &#34;&#34;&#34;
    def __init__(self, label=None, class_id: int=None, name: str=None, binary: int=False, **kwargs):

        super().__init__(label, class_id, name, binary, **kwargs)
        self._nodata_id = config.dataset.classes.class_id(&#39;nodata&#39;)
        self._total_class = self.add_weight(&#39;total_class&#39;, initializer=&#39;zeros&#39;)
        self._true_positives = self.add_weight(&#39;true_positives&#39;, initializer=&#39;zeros&#39;)

    def update_state(self, y_true, y_pred, sample_weight=None): #pylint: disable=unused-argument, arguments-differ
        y_true = tf.squeeze(y_true)
        right_class = tf.math.equal(y_true, self._label_id)
        if self._binary:
            y_pred = y_pred &gt;= 0.5
            right_class_pred = tf.squeeze(y_pred)
        else:
            y_pred = tf.math.argmax(y_pred, axis=-1)
            right_class_pred = tf.math.equal(y_pred, self._class_id)

        if self._nodata_id:
            valid = tf.math.not_equal(y_true, self._nodata_id)
            right_class_pred = tf.math.logical_and(right_class_pred, valid)

        total_class = tf.math.reduce_sum(tf.cast(right_class_pred, tf.float32))
        self._total_class.assign_add(total_class)
        true_positives = tf.math.logical_and(right_class, right_class_pred)
        true_positives = tf.math.reduce_sum(tf.cast(true_positives, tf.float32))
        self._true_positives.assign_add(true_positives)

    def result(self):
        return tf.math.divide_no_nan(self._true_positives, self._total_class)

class SparseBinaryAccuracy(SparseMetric): # pragma: no cover
    &#34;&#34;&#34;
    Accuracy.
    &#34;&#34;&#34;
    def __init__(self, label=None, class_id: int=None, name: str=None, binary: int=False, **kwargs):
        super().__init__(label, class_id, name, binary, **kwargs)
        self._nodata_id = config.dataset.classes.class_id(&#39;nodata&#39;)
        self._total = self.add_weight(&#39;total&#39;, initializer=&#39;zeros&#39;)
        self._correct = self.add_weight(&#39;correct&#39;, initializer=&#39;zeros&#39;)

    def update_state(self, y_true, y_pred, sample_weight=None): #pylint: disable=unused-argument, arguments-differ
        y_true = tf.squeeze(y_true)
        right_class = tf.math.equal(y_true, self._label_id)
        if self._binary:
            y_pred = y_pred &gt;= 0.5
            right_class_pred = tf.squeeze(y_pred)
        else:
            y_pred = tf.math.argmax(y_pred, axis=-1)
            right_class_pred = tf.math.equal(y_pred, self._class_id)

        true_positives = tf.math.logical_and(right_class, right_class_pred)
        false_negatives = tf.math.logical_and(tf.math.logical_not(right_class), tf.math.logical_not(right_class_pred))
        if self._nodata_id:
            valid = tf.math.not_equal(y_true, self._nodata_id)
            true_positives = tf.math.logical_and(true_positives, valid)
            false_negatives = tf.math.logical_and(false_negatives, valid)
            total = tf.math.reduce_sum(tf.cast(valid, tf.float32))
        else:
            total = tf.size(y_true)

        true_positives = tf.math.reduce_sum(tf.cast(true_positives, tf.float32))
        false_negatives = tf.math.reduce_sum(tf.cast(false_negatives, tf.float32))
        self._correct.assign_add(true_positives + false_negatives)
        self._total.assign_add(total)

    def result(self):
        return tf.math.divide(self._correct, self._total)

register_metric(&#39;SparseRecall&#39;, SparseRecall)
register_metric(&#39;SparsePrecision&#39;, SparsePrecision)
register_metric(&#39;SparseBinaryAccuracy&#39;, SparseBinaryAccuracy)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="delta.extensions.metrics.SparseBinaryAccuracy"><code class="flex name class">
<span>class <span class="ident">SparseBinaryAccuracy</span></span>
<span>(</span><span>label=None, class_id: int = None, name: str = None, binary: int = False, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Accuracy.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>label</code></strong></dt>
<dd>A class identifier accepted by <code><a title="delta.imagery.imagery_config.ClassesConfig.class_id" href="../imagery/imagery_config.html#delta.imagery.imagery_config.ClassesConfig.class_id">ClassesConfig.class_id()</a></code>.
Compared to valuse in the label image.</dd>
<dt><strong><code>class_id</code></strong> :&ensp;<code>Optional[int]</code></dt>
<dd>For multi-class one-hot outputs, used if the output class ID is different than the
one in the label image.</dd>
<dt><strong><code>label_id</code></strong> :&ensp;<code>Optional[int]</code></dt>
<dd>Internal use only, for reconstructing this class from a .savedmodel format</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Metric name.</dd>
<dt><strong><code>binary</code></strong> :&ensp;<code>bool</code></dt>
<dd>Use binary threshold (0.5) (one input, two classes) or argmax on one-hot encoding (one input per class).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SparseBinaryAccuracy(SparseMetric): # pragma: no cover
    &#34;&#34;&#34;
    Accuracy.
    &#34;&#34;&#34;
    def __init__(self, label=None, class_id: int=None, name: str=None, binary: int=False, **kwargs):
        super().__init__(label, class_id, name, binary, **kwargs)
        self._nodata_id = config.dataset.classes.class_id(&#39;nodata&#39;)
        self._total = self.add_weight(&#39;total&#39;, initializer=&#39;zeros&#39;)
        self._correct = self.add_weight(&#39;correct&#39;, initializer=&#39;zeros&#39;)

    def update_state(self, y_true, y_pred, sample_weight=None): #pylint: disable=unused-argument, arguments-differ
        y_true = tf.squeeze(y_true)
        right_class = tf.math.equal(y_true, self._label_id)
        if self._binary:
            y_pred = y_pred &gt;= 0.5
            right_class_pred = tf.squeeze(y_pred)
        else:
            y_pred = tf.math.argmax(y_pred, axis=-1)
            right_class_pred = tf.math.equal(y_pred, self._class_id)

        true_positives = tf.math.logical_and(right_class, right_class_pred)
        false_negatives = tf.math.logical_and(tf.math.logical_not(right_class), tf.math.logical_not(right_class_pred))
        if self._nodata_id:
            valid = tf.math.not_equal(y_true, self._nodata_id)
            true_positives = tf.math.logical_and(true_positives, valid)
            false_negatives = tf.math.logical_and(false_negatives, valid)
            total = tf.math.reduce_sum(tf.cast(valid, tf.float32))
        else:
            total = tf.size(y_true)

        true_positives = tf.math.reduce_sum(tf.cast(true_positives, tf.float32))
        false_negatives = tf.math.reduce_sum(tf.cast(false_negatives, tf.float32))
        self._correct.assign_add(true_positives + false_negatives)
        self._total.assign_add(total)

    def result(self):
        return tf.math.divide(self._correct, self._total)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="delta.extensions.metrics.SparseMetric" href="#delta.extensions.metrics.SparseMetric">SparseMetric</a></li>
<li>keras.metrics.base_metric.Metric</li>
<li>keras.engine.base_layer.Layer</li>
<li>tensorflow.python.module.module.Module</li>
<li>tensorflow.python.training.tracking.autotrackable.AutoTrackable</li>
<li>tensorflow.python.training.tracking.base.Trackable</li>
<li>keras.utils.version_utils.LayerVersionSelector</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="delta.extensions.metrics.SparseBinaryAccuracy.result"><code class="name flex">
<span>def <span class="ident">result</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Computes and returns the scalar metric value tensor or a dict of scalars.</p>
<p>Result computation is an idempotent operation that simply calculates the
metric value using the state variables.</p>
<h2 id="returns">Returns</h2>
<p>A scalar tensor, or a dictionary of scalar tensors.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def result(self):
    return tf.math.divide(self._correct, self._total)</code></pre>
</details>
</dd>
<dt id="delta.extensions.metrics.SparseBinaryAccuracy.update_state"><code class="name flex">
<span>def <span class="ident">update_state</span></span>(<span>self, y_true, y_pred, sample_weight=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Accumulates statistics for the metric.</p>
<p>Note: This function is executed as a graph function in graph mode.
This means:
a) Operations on the same resource are executed in textual order.
This should make it easier to do things like add the updated
value of a variable to another, for example.
b) You don't need to worry about collecting the update ops to execute.
All update ops added to the graph by this function will be executed.
As a result, code should generally work the same way with graph or
eager execution.</p>
<h2 id="args">Args</h2>
<dl>
<dt>*args:</dt>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>A mini-batch of inputs to the Metric.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_state(self, y_true, y_pred, sample_weight=None): #pylint: disable=unused-argument, arguments-differ
    y_true = tf.squeeze(y_true)
    right_class = tf.math.equal(y_true, self._label_id)
    if self._binary:
        y_pred = y_pred &gt;= 0.5
        right_class_pred = tf.squeeze(y_pred)
    else:
        y_pred = tf.math.argmax(y_pred, axis=-1)
        right_class_pred = tf.math.equal(y_pred, self._class_id)

    true_positives = tf.math.logical_and(right_class, right_class_pred)
    false_negatives = tf.math.logical_and(tf.math.logical_not(right_class), tf.math.logical_not(right_class_pred))
    if self._nodata_id:
        valid = tf.math.not_equal(y_true, self._nodata_id)
        true_positives = tf.math.logical_and(true_positives, valid)
        false_negatives = tf.math.logical_and(false_negatives, valid)
        total = tf.math.reduce_sum(tf.cast(valid, tf.float32))
    else:
        total = tf.size(y_true)

    true_positives = tf.math.reduce_sum(tf.cast(true_positives, tf.float32))
    false_negatives = tf.math.reduce_sum(tf.cast(false_negatives, tf.float32))
    self._correct.assign_add(true_positives + false_negatives)
    self._total.assign_add(total)</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="delta.extensions.metrics.SparseMetric" href="#delta.extensions.metrics.SparseMetric">SparseMetric</a></b></code>:
<ul class="hlist">
<li><code><a title="delta.extensions.metrics.SparseMetric.get_config" href="#delta.extensions.metrics.SparseMetric.get_config">get_config</a></code></li>
<li><code><a title="delta.extensions.metrics.SparseMetric.reset_state" href="#delta.extensions.metrics.SparseMetric.reset_state">reset_state</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="delta.extensions.metrics.SparseMetric"><code class="flex name class">
<span>class <span class="ident">SparseMetric</span></span>
<span>(</span><span>label=None, class_id: int = None, name: str = None, binary: int = False, label_id: int = None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>An abstract class for metrics applied to integer class labels,
with networks that output one-hot encoding.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>label</code></strong></dt>
<dd>A class identifier accepted by <code><a title="delta.imagery.imagery_config.ClassesConfig.class_id" href="../imagery/imagery_config.html#delta.imagery.imagery_config.ClassesConfig.class_id">ClassesConfig.class_id()</a></code>.
Compared to valuse in the label image.</dd>
<dt><strong><code>class_id</code></strong> :&ensp;<code>Optional[int]</code></dt>
<dd>For multi-class one-hot outputs, used if the output class ID is different than the
one in the label image.</dd>
<dt><strong><code>label_id</code></strong> :&ensp;<code>Optional[int]</code></dt>
<dd>Internal use only, for reconstructing this class from a .savedmodel format</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Metric name.</dd>
<dt><strong><code>binary</code></strong> :&ensp;<code>bool</code></dt>
<dd>Use binary threshold (0.5) (one input, two classes) or argmax on one-hot encoding (one input per class).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SparseMetric(tensorflow.keras.metrics.Metric): # pylint:disable=abstract-method # pragma: no cover
    &#34;&#34;&#34;
    An abstract class for metrics applied to integer class labels,
    with networks that output one-hot encoding.
    &#34;&#34;&#34;
    def __init__(self, label=None, class_id: int=None, name: str=None, binary: int=False, label_id: int=None, **kwargs):
        &#34;&#34;&#34;
        Parameters
        ----------
        label
            A class identifier accepted by `delta.imagery.imagery_config.ClassesConfig.class_id`.
            Compared to valuse in the label image.
        class_id: Optional[int]
            For multi-class one-hot outputs, used if the output class ID is different than the
            one in the label image.
        label_id: Optional[int]
            Internal use only, for reconstructing this class from a .savedmodel format
        name: str
            Metric name.
        binary: bool
            Use binary threshold (0.5) (one input, two classes) or argmax on one-hot encoding (one input per class).
        &#34;&#34;&#34;
        super().__init__(name=name, **kwargs)
        self._binary = binary
        self._label_id = config.dataset.classes.class_id(label) if label_id is None else label_id
        self._class_id = class_id if class_id is not None else self._label_id

    def reset_state(self):
        for s in self.variables:
            s.assign(tf.zeros(shape=s.shape))

    def get_config(self):
        cfg = super().get_config()
        cfg.update({&#39;binary&#39;: self._binary, &#39;class_id&#39;: self._class_id, &#39;label_id&#39;: self._label_id})
        return cfg</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>keras.metrics.base_metric.Metric</li>
<li>keras.engine.base_layer.Layer</li>
<li>tensorflow.python.module.module.Module</li>
<li>tensorflow.python.training.tracking.autotrackable.AutoTrackable</li>
<li>tensorflow.python.training.tracking.base.Trackable</li>
<li>keras.utils.version_utils.LayerVersionSelector</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="delta.extensions.metrics.SparseBinaryAccuracy" href="#delta.extensions.metrics.SparseBinaryAccuracy">SparseBinaryAccuracy</a></li>
<li><a title="delta.extensions.metrics.SparsePrecision" href="#delta.extensions.metrics.SparsePrecision">SparsePrecision</a></li>
<li><a title="delta.extensions.metrics.SparseRecall" href="#delta.extensions.metrics.SparseRecall">SparseRecall</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="delta.extensions.metrics.SparseMetric.get_config"><code class="name flex">
<span>def <span class="ident">get_config</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the serializable config of the metric.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_config(self):
    cfg = super().get_config()
    cfg.update({&#39;binary&#39;: self._binary, &#39;class_id&#39;: self._class_id, &#39;label_id&#39;: self._label_id})
    return cfg</code></pre>
</details>
</dd>
<dt id="delta.extensions.metrics.SparseMetric.reset_state"><code class="name flex">
<span>def <span class="ident">reset_state</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Resets all of the metric state variables.</p>
<p>This function is called between epochs/steps,
when a metric is evaluated during training.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset_state(self):
    for s in self.variables:
        s.assign(tf.zeros(shape=s.shape))</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="delta.extensions.metrics.SparsePrecision"><code class="flex name class">
<span>class <span class="ident">SparsePrecision</span></span>
<span>(</span><span>label=None, class_id: int = None, name: str = None, binary: int = False, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Precision.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>label</code></strong></dt>
<dd>A class identifier accepted by <code><a title="delta.imagery.imagery_config.ClassesConfig.class_id" href="../imagery/imagery_config.html#delta.imagery.imagery_config.ClassesConfig.class_id">ClassesConfig.class_id()</a></code>.
Compared to valuse in the label image.</dd>
<dt><strong><code>class_id</code></strong> :&ensp;<code>Optional[int]</code></dt>
<dd>For multi-class one-hot outputs, used if the output class ID is different than the
one in the label image.</dd>
<dt><strong><code>label_id</code></strong> :&ensp;<code>Optional[int]</code></dt>
<dd>Internal use only, for reconstructing this class from a .savedmodel format</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Metric name.</dd>
<dt><strong><code>binary</code></strong> :&ensp;<code>bool</code></dt>
<dd>Use binary threshold (0.5) (one input, two classes) or argmax on one-hot encoding (one input per class).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SparsePrecision(SparseMetric): # pragma: no cover
    &#34;&#34;&#34;
    Precision.
    &#34;&#34;&#34;
    def __init__(self, label=None, class_id: int=None, name: str=None, binary: int=False, **kwargs):

        super().__init__(label, class_id, name, binary, **kwargs)
        self._nodata_id = config.dataset.classes.class_id(&#39;nodata&#39;)
        self._total_class = self.add_weight(&#39;total_class&#39;, initializer=&#39;zeros&#39;)
        self._true_positives = self.add_weight(&#39;true_positives&#39;, initializer=&#39;zeros&#39;)

    def update_state(self, y_true, y_pred, sample_weight=None): #pylint: disable=unused-argument, arguments-differ
        y_true = tf.squeeze(y_true)
        right_class = tf.math.equal(y_true, self._label_id)
        if self._binary:
            y_pred = y_pred &gt;= 0.5
            right_class_pred = tf.squeeze(y_pred)
        else:
            y_pred = tf.math.argmax(y_pred, axis=-1)
            right_class_pred = tf.math.equal(y_pred, self._class_id)

        if self._nodata_id:
            valid = tf.math.not_equal(y_true, self._nodata_id)
            right_class_pred = tf.math.logical_and(right_class_pred, valid)

        total_class = tf.math.reduce_sum(tf.cast(right_class_pred, tf.float32))
        self._total_class.assign_add(total_class)
        true_positives = tf.math.logical_and(right_class, right_class_pred)
        true_positives = tf.math.reduce_sum(tf.cast(true_positives, tf.float32))
        self._true_positives.assign_add(true_positives)

    def result(self):
        return tf.math.divide_no_nan(self._true_positives, self._total_class)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="delta.extensions.metrics.SparseMetric" href="#delta.extensions.metrics.SparseMetric">SparseMetric</a></li>
<li>keras.metrics.base_metric.Metric</li>
<li>keras.engine.base_layer.Layer</li>
<li>tensorflow.python.module.module.Module</li>
<li>tensorflow.python.training.tracking.autotrackable.AutoTrackable</li>
<li>tensorflow.python.training.tracking.base.Trackable</li>
<li>keras.utils.version_utils.LayerVersionSelector</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="delta.extensions.metrics.SparsePrecision.result"><code class="name flex">
<span>def <span class="ident">result</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Computes and returns the scalar metric value tensor or a dict of scalars.</p>
<p>Result computation is an idempotent operation that simply calculates the
metric value using the state variables.</p>
<h2 id="returns">Returns</h2>
<p>A scalar tensor, or a dictionary of scalar tensors.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def result(self):
    return tf.math.divide_no_nan(self._true_positives, self._total_class)</code></pre>
</details>
</dd>
<dt id="delta.extensions.metrics.SparsePrecision.update_state"><code class="name flex">
<span>def <span class="ident">update_state</span></span>(<span>self, y_true, y_pred, sample_weight=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Accumulates statistics for the metric.</p>
<p>Note: This function is executed as a graph function in graph mode.
This means:
a) Operations on the same resource are executed in textual order.
This should make it easier to do things like add the updated
value of a variable to another, for example.
b) You don't need to worry about collecting the update ops to execute.
All update ops added to the graph by this function will be executed.
As a result, code should generally work the same way with graph or
eager execution.</p>
<h2 id="args">Args</h2>
<dl>
<dt>*args:</dt>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>A mini-batch of inputs to the Metric.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_state(self, y_true, y_pred, sample_weight=None): #pylint: disable=unused-argument, arguments-differ
    y_true = tf.squeeze(y_true)
    right_class = tf.math.equal(y_true, self._label_id)
    if self._binary:
        y_pred = y_pred &gt;= 0.5
        right_class_pred = tf.squeeze(y_pred)
    else:
        y_pred = tf.math.argmax(y_pred, axis=-1)
        right_class_pred = tf.math.equal(y_pred, self._class_id)

    if self._nodata_id:
        valid = tf.math.not_equal(y_true, self._nodata_id)
        right_class_pred = tf.math.logical_and(right_class_pred, valid)

    total_class = tf.math.reduce_sum(tf.cast(right_class_pred, tf.float32))
    self._total_class.assign_add(total_class)
    true_positives = tf.math.logical_and(right_class, right_class_pred)
    true_positives = tf.math.reduce_sum(tf.cast(true_positives, tf.float32))
    self._true_positives.assign_add(true_positives)</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="delta.extensions.metrics.SparseMetric" href="#delta.extensions.metrics.SparseMetric">SparseMetric</a></b></code>:
<ul class="hlist">
<li><code><a title="delta.extensions.metrics.SparseMetric.get_config" href="#delta.extensions.metrics.SparseMetric.get_config">get_config</a></code></li>
<li><code><a title="delta.extensions.metrics.SparseMetric.reset_state" href="#delta.extensions.metrics.SparseMetric.reset_state">reset_state</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="delta.extensions.metrics.SparseRecall"><code class="flex name class">
<span>class <span class="ident">SparseRecall</span></span>
<span>(</span><span>label=None, class_id: int = None, name: str = None, binary: int = False, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Recall.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>label</code></strong></dt>
<dd>A class identifier accepted by <code><a title="delta.imagery.imagery_config.ClassesConfig.class_id" href="../imagery/imagery_config.html#delta.imagery.imagery_config.ClassesConfig.class_id">ClassesConfig.class_id()</a></code>.
Compared to valuse in the label image.</dd>
<dt><strong><code>class_id</code></strong> :&ensp;<code>Optional[int]</code></dt>
<dd>For multi-class one-hot outputs, used if the output class ID is different than the
one in the label image.</dd>
<dt><strong><code>label_id</code></strong> :&ensp;<code>Optional[int]</code></dt>
<dd>Internal use only, for reconstructing this class from a .savedmodel format</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Metric name.</dd>
<dt><strong><code>binary</code></strong> :&ensp;<code>bool</code></dt>
<dd>Use binary threshold (0.5) (one input, two classes) or argmax on one-hot encoding (one input per class).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SparseRecall(SparseMetric): # pragma: no cover
    &#34;&#34;&#34;
    Recall.
    &#34;&#34;&#34;
    def __init__(self, label=None, class_id: int=None, name: str=None, binary: int=False, **kwargs):

        super().__init__(label, class_id, name, binary, **kwargs)
        self._total_class = self.add_weight(&#39;total_class&#39;, initializer=&#39;zeros&#39;)
        self._true_positives = self.add_weight(&#39;true_positives&#39;, initializer=&#39;zeros&#39;)

    # sample_weight is unused but required by tensorflow
    def update_state(self, y_true, y_pred, sample_weight=None): #pylint: disable=unused-argument, arguments-differ
        y_true = tf.squeeze(y_true)
        right_class = tf.math.equal(y_true, self._label_id)
        if self._binary:
            y_pred = y_pred &gt;= 0.5
            right_class_pred = tf.squeeze(y_pred)
        else:
            y_pred = tf.math.argmax(y_pred, axis=-1)
            right_class_pred = tf.math.equal(y_pred, self._class_id)
        total_class = tf.math.reduce_sum(tf.cast(right_class, tf.float32))
        self._total_class.assign_add(total_class)
        true_positives = tf.math.logical_and(right_class, right_class_pred)
        true_positives = tf.math.reduce_sum(tf.cast(true_positives, tf.float32))
        self._true_positives.assign_add(true_positives)

    def result(self):
        return tf.math.divide_no_nan(self._true_positives, self._total_class)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="delta.extensions.metrics.SparseMetric" href="#delta.extensions.metrics.SparseMetric">SparseMetric</a></li>
<li>keras.metrics.base_metric.Metric</li>
<li>keras.engine.base_layer.Layer</li>
<li>tensorflow.python.module.module.Module</li>
<li>tensorflow.python.training.tracking.autotrackable.AutoTrackable</li>
<li>tensorflow.python.training.tracking.base.Trackable</li>
<li>keras.utils.version_utils.LayerVersionSelector</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="delta.extensions.metrics.SparseRecall.result"><code class="name flex">
<span>def <span class="ident">result</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Computes and returns the scalar metric value tensor or a dict of scalars.</p>
<p>Result computation is an idempotent operation that simply calculates the
metric value using the state variables.</p>
<h2 id="returns">Returns</h2>
<p>A scalar tensor, or a dictionary of scalar tensors.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def result(self):
    return tf.math.divide_no_nan(self._true_positives, self._total_class)</code></pre>
</details>
</dd>
<dt id="delta.extensions.metrics.SparseRecall.update_state"><code class="name flex">
<span>def <span class="ident">update_state</span></span>(<span>self, y_true, y_pred, sample_weight=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Accumulates statistics for the metric.</p>
<p>Note: This function is executed as a graph function in graph mode.
This means:
a) Operations on the same resource are executed in textual order.
This should make it easier to do things like add the updated
value of a variable to another, for example.
b) You don't need to worry about collecting the update ops to execute.
All update ops added to the graph by this function will be executed.
As a result, code should generally work the same way with graph or
eager execution.</p>
<h2 id="args">Args</h2>
<dl>
<dt>*args:</dt>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>A mini-batch of inputs to the Metric.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_state(self, y_true, y_pred, sample_weight=None): #pylint: disable=unused-argument, arguments-differ
    y_true = tf.squeeze(y_true)
    right_class = tf.math.equal(y_true, self._label_id)
    if self._binary:
        y_pred = y_pred &gt;= 0.5
        right_class_pred = tf.squeeze(y_pred)
    else:
        y_pred = tf.math.argmax(y_pred, axis=-1)
        right_class_pred = tf.math.equal(y_pred, self._class_id)
    total_class = tf.math.reduce_sum(tf.cast(right_class, tf.float32))
    self._total_class.assign_add(total_class)
    true_positives = tf.math.logical_and(right_class, right_class_pred)
    true_positives = tf.math.reduce_sum(tf.cast(true_positives, tf.float32))
    self._true_positives.assign_add(true_positives)</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="delta.extensions.metrics.SparseMetric" href="#delta.extensions.metrics.SparseMetric">SparseMetric</a></b></code>:
<ul class="hlist">
<li><code><a title="delta.extensions.metrics.SparseMetric.get_config" href="#delta.extensions.metrics.SparseMetric.get_config">get_config</a></code></li>
<li><code><a title="delta.extensions.metrics.SparseMetric.reset_state" href="#delta.extensions.metrics.SparseMetric.reset_state">reset_state</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="delta.extensions" href="index.html">delta.extensions</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="delta.extensions.metrics.SparseBinaryAccuracy" href="#delta.extensions.metrics.SparseBinaryAccuracy">SparseBinaryAccuracy</a></code></h4>
<ul class="">
<li><code><a title="delta.extensions.metrics.SparseBinaryAccuracy.result" href="#delta.extensions.metrics.SparseBinaryAccuracy.result">result</a></code></li>
<li><code><a title="delta.extensions.metrics.SparseBinaryAccuracy.update_state" href="#delta.extensions.metrics.SparseBinaryAccuracy.update_state">update_state</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="delta.extensions.metrics.SparseMetric" href="#delta.extensions.metrics.SparseMetric">SparseMetric</a></code></h4>
<ul class="">
<li><code><a title="delta.extensions.metrics.SparseMetric.get_config" href="#delta.extensions.metrics.SparseMetric.get_config">get_config</a></code></li>
<li><code><a title="delta.extensions.metrics.SparseMetric.reset_state" href="#delta.extensions.metrics.SparseMetric.reset_state">reset_state</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="delta.extensions.metrics.SparsePrecision" href="#delta.extensions.metrics.SparsePrecision">SparsePrecision</a></code></h4>
<ul class="">
<li><code><a title="delta.extensions.metrics.SparsePrecision.result" href="#delta.extensions.metrics.SparsePrecision.result">result</a></code></li>
<li><code><a title="delta.extensions.metrics.SparsePrecision.update_state" href="#delta.extensions.metrics.SparsePrecision.update_state">update_state</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="delta.extensions.metrics.SparseRecall" href="#delta.extensions.metrics.SparseRecall">SparseRecall</a></code></h4>
<ul class="">
<li><code><a title="delta.extensions.metrics.SparseRecall.result" href="#delta.extensions.metrics.SparseRecall.result">result</a></code></li>
<li><code><a title="delta.extensions.metrics.SparseRecall.update_state" href="#delta.extensions.metrics.SparseRecall.update_state">update_state</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>