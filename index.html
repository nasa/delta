<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>delta API documentation</title>
<meta name="description" content="**DELTA** (Deep Earth Learning, Tools, and Analysis) is a framework for deep learning on satellite imagery,
based on Tensorflow. DELTA classifies …" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Package <code>delta</code></h1>
</header>
<section id="section-intro">
<p><strong>DELTA</strong> (Deep Earth Learning, Tools, and Analysis) is a framework for deep learning on satellite imagery,
based on Tensorflow. DELTA classifies large satellite images with neural networks, automatically handling
tiling large imagery.</p>
<p><img alt="DELTA example flowchart" src="delta/../docs/delta_flowchart.png"></p>
<p>DELTA is under active development by the
<a href="https://ti.arc.nasa.gov/tech/asr/groups/intelligent-robotics/">NASA Ames Intelligent Robotics Group</a> through the end of 2021.
Initially, it is mapping floods for disaster response, in collaboration with the
<a href="http://www.usgs.gov">U.S. Geological Survey</a>, <a href="https://www.nga.mil/">National Geospatial Intelligence Agency</a>,
<a href="http://www.ncsa.illinois.edu/">National Center for Supercomputing Applications</a>, and
<a href="https://www.ua.edu/">University of Alabama</a>.</p>
<h1 id="installation">Installation</h1>
<ol>
<li>
<p>Install <a href="https://www.python.org/downloads/">python3</a>, <a href="https://gdal.org/download.html">GDAL</a>,
and the <a href="https://pypi.org/project/GDAL/">GDAL python bindings</a>. For Ubuntu Linux, you can run
<code>scripts/setup.sh</code> from the DELTA repository to install these dependencies.</p>
</li>
<li>
<p>Install Tensorflow following the <a href="https://www.tensorflow.org/install">instructions</a>. For
GPU support in DELTA (highly recommended) follow the directions in the
<a href="https://www.tensorflow.org/install/gpu">GPU guide</a>.</p>
</li>
<li>
<p>Checkout the delta repository and install with pip:</p>
<p><code>bash
git clone &lt;http://github.com/nasa/delta&gt;
python3 -m pip install delta</code></p>
</li>
</ol>
<p>DELTA is now installed and ready to use!</p>
<h3 id="alternate-install-using-a-conda-environment">Alternate install using a Conda environment</h3>
<ol>
<li>
<p>Install <a href="https://docs.conda.io/en/latest/miniconda.html">Miniconda</a>.</p>
</li>
<li>
<p>Checkout the delta repository and cd into the directory:
<code>git clone &lt;http://github.com/nasa/delta&gt;
cd ./delta</code></p>
</li>
<li>
<p>Run the following commands to create a conda environment, install dependences, and install delta:
<code>bash
conda create --name delta --yes python gdal
conda activate delta
pip install . # This command should be run in the ./delta directory we made in step 2</code></p>
</li>
<li>For GPU support in DELTA you'll need to install the <a href="https://www.tensorflow.org/install/gpu#software_requirements">required NVIDIA software</a> before running the conda commands in step 3.</li>
</ol>
<h3 id="installing-esa-snap">Installing ESA SNAP</h3>
<p>In order to process Sentinel-1 images you will need to instal the ESA SNAP tool.
You can download it here:
<code>https://step.esa.int/main/download/snap-download/</code></p>
<p>Once it is installed, you will need to add SNAP's bin folder to your path like this:
<code>export PATH=$PATH:/where/you/installed/snap/bin</code></p>
<h1 id="documentation">Documentation</h1>
<ul>
<li>README Docs</li>
<li><a href="delta/config/README.md">DELTA Config README</a> - details on how to configure DELTA from the command line using .yaml files.</li>
<li><a href="delta/config/networks/README.md">DELTA built-in networks README</a> - details some of the available network architecture .yaml files already included with DELTA. </li>
<li><a href="https://nasa.github.io/delta/">Python Documentation</a> - DELTA can be used either as a command line tool or as a python library. You can view the documentation at the linked URL or generate the documentation with <a href="scripts/docs.sh"><code>scripts/docs.sh</code></a>.</li>
<li><code>delta.config.extensions</code> <a href="https://nasa.github.io/delta/config/extensions.html">documentation</a> - details on extending DELTA for use with custom layers, image types, preprocessing, etc.</li>
</ul>
<h1 id="example">Example</h1>
<h3 id="bash-script-example-linux-only">Bash Script Example (Linux Only)</h3>
<p>As a simple example, consider training a neural network to map clouds with Landsat-8 images.
The script <a href="scripts/example/l8_cloud.sh"><code>scripts/example/l8_cloud.sh</code></a> trains such a network using DELTA from the
<a href="https://www.usgs.gov/core-science-systems/nli/landsat/spatial-procedures-automated-removal-cloud-and-shadow-sparcs">USGS SPARCS dataset</a>,
and shows how DELTA can be used. The steps involved in this, and other, classification processes are:</p>
<ol>
<li>
<p><strong>Collect</strong> training data. The SPARCS dataset contains Landsat-8 imagery with and without clouds.</p>
</li>
<li>
<p><strong>Label</strong> training data. The SPARCS labels classify each pixel according to cloud, land, water and other classes.</p>
</li>
<li>
<p><strong>Train</strong> the neural network. The script <code>scripts/example/l8_cloud.sh</code> invokes the command</p>
<p><code>delta train --config l8_cloud.yaml l8_clouds.h5</code></p>
<p>where <code>scripts/example/l8_cloud.yaml</code> is a configuration file specifying the labeled training data and
training parameters (learn more about configuration files below). A neural network file
<code>l8_clouds.h5</code> is output.</p>
</li>
<li>
<p><strong>Classify</strong> with the trained network. The script runs</p>
<p><code>delta classify --config l8_cloud.yaml --image-dir ./validate --overlap 32 l8_clouds.h5</code></p>
<p>to classify the images in the <code>validate</code> folder using the network <code>l8_clouds.h5</code> learned previously.
The overlap tiles to ignore border regions when possible to make a more aesthetically pleasing classified
image. The command outputs a predicted image and confusion matrix.</p>
</li>
</ol>
<p>The results could be improved&mdash; with more training, more data, an improved network, or more&mdash; but this
example shows the basic usage of DETLA.</p>
<h3 id="jupyterlab-example-linuxmac">JupyterLab Example (Linux/Mac)</h3>
<p>The <a href="scripts/example/l8_cloud_example.ipynb">jupyter lab example</a> is very similar to the bash script example above but has a more visual demonstration of the steps and imagery used. It is especially helpful if you are less experienced with the command line.</p>
<p>You can view a read-only version at the above link. Or if you'd like to run the example yourself you'll need to install JupyterLab. To do that you can simply run </p>
<p><code>pip install jupyterlab</code> </p>
<p>after <a href="#Installation">installing DELTA using the above instructions.</a> Then run </p>
<p><code>jupyter-lab path_to_delta_install/scripts/example/l8_cloud_example.ipynb</code> </p>
<p>Once jupyter loads, you can advance through the cells one by one using the "play" button </p>
<p><img src="docs/jupyter_play.png" width="300"/></p>
<p>or run all the cells at once using the "fast-foward" button.</p>
<p><img src="docs/jupyter_fastforward.png" width="300"/></p>
<h1 id="configuration-and-extensions">Configuration and Extensions</h1>
<p>DELTA provides many options for customizing data inputs and training. All options are configured via
YAML files. Some options can be overwritten with command line options (use
<code>delta --help</code> to see which). See the <a href="delta/config/README.md"><code>delta.config</code> README</a> to learn about available configuration
options.</p>
<p>DELTA can be extended to support custom neural network layers, image types, preprocessing operations, metrics, losses,
and training callbacks. Learn about DELTA extensions in the <code>delta.config.extensions</code> <a href="https://nasa.github.io/delta/config/extensions.html">documentation</a>.</p>
<h1 id="data-management">Data Management</h1>
<p>DELTA integrates with <a href="http://mlflow.org">MLFlow</a> to track training. MLFlow options can
be specified in the corresponding area of the configuration file. By default, training and
validation metrics are logged, along with all configuration parameters. The most recent neural
network is saved to a file when the training program is interrupted or completes.</p>
<p>View all the logged training information through mlflow by running::</p>
<pre><code>  delta mlflow_ui
</code></pre>
<p>and navigating to the printed URL in a browser. This makes it easier to keep track when running
experiments and adjusting parameters.</p>
<h1 id="data-preparation">Data Preparation</h1>
<p>By default DELTA operates on compressed input images which are unpacked to a temporary cache before
they are processed.
You can speed up processing by pre-unpacking your input data to a new folder
using the tool <a href="scripts/fetch/unpack_inputs.py">scripts/fetch/unpack_inputs.py</a> as in this example:</p>
<pre><code>  python3 scripts/fetch/unpack_inputs.py --input-folder raw_images --output-folder unpacked_images \
  --image-type worldview --image-ext .zip
</code></pre>
<p>The images will be unpacked in the output folder, ready for training or classification. To train or
classify with unpacked data, the image type specified in the configuration file remains the same but
the extension should match the new extension in the unpacked folders (.tif for worldview, .vrt for Sentinel1).</p>
<h1 id="contributors">Contributors</h1>
<p>We welcome pull requests to contribute to DELTA. However, due to NASA legal restrictions, we must require
that all contributors sign and submit a
<a href="https://www.nasa.gov/sites/default/files/atoms/files/astrobee_individual_contributor_license_agreement.pdf">NASA Individual Contributor License Agreement</a>.
You can scan the document and submit via email. Thank you for your understanding.</p>
<p>Important notes for developers:</p>
<ul>
<li>
<p><strong>Branching</strong>: Active development occurs on <code>develop</code>. Releases are pushed to <code>master</code>.</p>
</li>
<li>
<p><strong>Code Style</strong>: Code must pass our linter before merging. Run <a href="scripts/linter/install_linter.sh"><code>scripts/linter/install_linter.sh</code></a> to install
the linter as a git pre-commit hook.</p>
</li>
<li>
<p><strong>Unit Tests</strong>: Code must pass unit tests before merging. Run <code>pytest</code> in the <code>tests</code> directory to run the tests.
Please add new unit tests as appropriate.</p>
</li>
<li>
<p><strong>Development Setup</strong>: You can install delta using pip's <code>-e</code> flag which installs in editable mode. Then you can
run <code><a title="delta" href="#delta">delta</a></code> and it will use your latest changes made to the repo without reinstalling.</p>
</li>
</ul>
<h1 id="licensing">Licensing</h1>
<p>DELTA is released under the Apache 2 license.</p>
<p>Copyright (c) 2020, United States Government, as represented by the Administrator of the National Aeronautics and Space Administration. All rights reserved.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># Copyright © 2020, United States Government, as represented by the
# Administrator of the National Aeronautics and Space Administration.
# All rights reserved.
#
# The DELTA (Deep Earth Learning, Tools, and Analysis) platform is
# licensed under the Apache License, Version 2.0 (the &#34;License&#34;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#        http://www.apache.org/licenses/LICENSE-2.0.
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &#34;AS IS&#34; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

&#39;&#39;&#39;
.. include:: ../README.md
&#39;&#39;&#39;

import sys

if sys.version_info &lt; (3, 6, 0):
    raise ImportError(f&#39;DELTA code requires Python version &gt;= 3.6.  Installed is {sys.version_info}&#39;)</code></pre>
</details>
</section>
<section>
<h2 class="section-title" id="header-submodules">Sub-modules</h2>
<dl>
<dt><code class="name"><a title="delta.config" href="config/index.html">delta.config</a></code></dt>
<dd>
<div class="desc"><p>Configuration via YAML files and command line options …</p></div>
</dd>
<dt><code class="name"><a title="delta.extensions" href="extensions/index.html">delta.extensions</a></code></dt>
<dd>
<div class="desc"><p>Module for extensions to DELTA …</p></div>
</dd>
<dt><code class="name"><a title="delta.imagery" href="imagery/index.html">delta.imagery</a></code></dt>
<dd>
<div class="desc"><p>Load and process imagery data sources …</p></div>
</dd>
<dt><code class="name"><a title="delta.ml" href="ml/index.html">delta.ml</a></code></dt>
<dd>
<div class="desc"><p>Module for machine learning given imagery data.</p></div>
</dd>
<dt><code class="name"><a title="delta.subcommands" href="subcommands/index.html">delta.subcommands</a></code></dt>
<dd>
<div class="desc"><p>Subcommands called from the main <code><a title="delta" href="#delta">delta</a></code> executable …</p></div>
</dd>
</dl>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul>
<li><a href="#installation">Installation</a><ul>
<li><a href="#alternate-install-using-a-conda-environment">Alternate install using a Conda environment</a></li>
<li><a href="#installing-esa-snap">Installing ESA SNAP</a></li>
</ul>
</li>
<li><a href="#documentation">Documentation</a></li>
<li><a href="#example">Example</a><ul>
<li><a href="#bash-script-example-linux-only">Bash Script Example (Linux Only)</a></li>
<li><a href="#jupyterlab-example-linuxmac">JupyterLab Example (Linux/Mac)</a></li>
</ul>
</li>
<li><a href="#configuration-and-extensions">Configuration and Extensions</a></li>
<li><a href="#data-management">Data Management</a></li>
<li><a href="#data-preparation">Data Preparation</a></li>
<li><a href="#contributors">Contributors</a></li>
<li><a href="#licensing">Licensing</a></li>
</ul>
</div>
<ul id="index">
<li><h3><a href="#header-submodules">Sub-modules</a></h3>
<ul>
<li><code><a title="delta.config" href="config/index.html">delta.config</a></code></li>
<li><code><a title="delta.extensions" href="extensions/index.html">delta.extensions</a></code></li>
<li><code><a title="delta.imagery" href="imagery/index.html">delta.imagery</a></code></li>
<li><code><a title="delta.ml" href="ml/index.html">delta.ml</a></code></li>
<li><code><a title="delta.subcommands" href="subcommands/index.html">delta.subcommands</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>