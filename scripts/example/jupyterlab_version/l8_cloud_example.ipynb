{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Landsat 8 Classification Example\n",
    "\n",
    "This example will walk you through an example of using DELTA to train a simple example model. You can use what you learn here to use DELTA on your own datasets and with your own model architectures.\n",
    "In this example you will:\n",
    "- Download a dataset of images and labels\n",
    "- Train a simple model using example configuration files\n",
    "- Examine results of the trained model\n",
    "- Make some changes to the configuration files and train a modified model\n",
    "- Examine the results of the modified model\n",
    "\n",
    "## Downloading and Extracting Dataset\n",
    "\n",
    "The dataset includes satellite images along with classification labels for different types of land cover (water, cloud, snow, etc.).\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fda33b66-8759-4600-96af-10328dfe09a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset.\n",
      "--2021-07-14 11:23:49--  https://landsat.usgs.gov/cloud-validation/sparcs/l8cloudmasks.zip\n",
      "Resolving landsat.usgs.gov (landsat.usgs.gov)... 152.61.136.10, 2001:49c8:4000:122c::10\n",
      "Connecting to landsat.usgs.gov (landsat.usgs.gov)|152.61.136.10|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1555733976 (1.4G) [application/zip]\n",
      "Saving to: 'l8cloudmasks.zip'\n",
      "\n",
      "l8cloudmasks.zip    100%[===================>]   1.45G  14.4MB/s    in 2m 47s  \n",
      "\n",
      "2021-07-14 11:26:36 (8.88 MB/s) - 'l8cloudmasks.zip' saved [1555733976/1555733976]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!echo \"Downloading dataset.\"\n",
    "!wget https://landsat.usgs.gov/cloud-validation/sparcs/l8cloudmasks.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we're extracting the dataset and organizing the images into folders.\n",
    "We are:\n",
    "- setting aside two images in a folder called \"validate\" to test our model later\n",
    "- moving the satellite images into a folder called \"train\"\n",
    "- moving the classification labels into a folder called \"labels\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f7c8cdb-0213-4382-8746-4dead4ae57f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset.\n"
     ]
    }
   ],
   "source": [
    "!echo \"Extracting dataset.\"\n",
    "!unzip -q l8cloudmasks.zip\n",
    "!mkdir validate\n",
    "!mv sending/LC82290562014157LGN00_24_data.tif sending/LC82210662014229LGN00_18_data.tif validate/\n",
    "!mkdir train\n",
    "!mv sending/*_data.tif train/\n",
    "!mkdir labels\n",
    "!mv sending/*_mask.png labels/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e6913ec-6e08-483e-989d-7fc7d0f6dfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " delta\t\t\t   l8_cloud.sh\t   sending\n",
      "'l8_cloud example.ipynb'   l8_cloud.yaml   train\n",
      " l8cloudmasks.zip\t   labels\t   validate\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf80050d-ca27-4e31-8d5b-a76f00ed6b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LC80010812013365LGN00_18_data.tif\n",
      "LC80020622013244LGN00_32_data.tif\n",
      "LC80050152014172LGN00_12_data.tif\n",
      "LC80050562014076LGN00_33_data.tif\n",
      "LC80150242014146LGN00_23_data.tif\n",
      "LC80190352014078LGN01_26_data.tif\n",
      "LC80200462014213LGN00_11_data.tif\n",
      "LC80250402013245LGN00_45_data.tif\n",
      "LC80250482014072LGN00_18_data.tif\n",
      "LC80310432013207LGN00_11_data.tif\n"
     ]
    }
   ],
   "source": [
    "!ls train/ | head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed0d005-6a9e-41a1-9582-18cbfc21084e",
   "metadata": {},
   "source": [
    "### Example Satellite Image\n",
    "<img src='example_screenshots/Screen Shot 2021-07-13 at 6.57.11 PM.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79a00a8c-7b1f-4609-9c7e-3947f4a14a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LC80010812013365LGN00_18_mask.png\n",
      "LC80020622013244LGN00_32_mask.png\n",
      "LC80050152014172LGN00_12_mask.png\n",
      "LC80050562014076LGN00_33_mask.png\n",
      "LC80150242014146LGN00_23_mask.png\n",
      "LC80190352014078LGN01_26_mask.png\n",
      "LC80200462014213LGN00_11_mask.png\n",
      "LC80250402013245LGN00_45_mask.png\n",
      "LC80250482014072LGN00_18_mask.png\n",
      "LC80310432013207LGN00_11_mask.png\n"
     ]
    }
   ],
   "source": [
    "!ls labels | head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e792438d-8a1a-4323-b24d-fce7488b65fd",
   "metadata": {},
   "source": [
    "### Example Label Image\n",
    "\n",
    "The different colors represent different land cover classifications.\n",
    "\n",
    "<img src='labels/LC80010812013365LGN00_18_mask.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09da9259-107c-4dc4-a284-a1fc780ab30f",
   "metadata": {},
   "source": [
    "## Training a Model\n",
    "\n",
    "We'll use the following configuration files which specify a dataset to use (l8_cloud_dataset.yaml) and a network architecture to train (l8_cloud_train_network.yaml).\n",
    "\n",
    "### Configuration YAMLs\n",
    "\n",
    "<a href='./l8_cloud_dataset.yaml' > l8_cloud_dataset.yaml </a><br />\n",
    "<a href='./l8_cloud_train_network.yaml' > l8_cloud_train_network.yaml </a>\n",
    "\n",
    "<a href='../../../delta/config/README.md' > Detailed Config Documentation </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8881b152-6c50-4ec2-b7a7-7d35db3cbb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "31/31 [==============================] - 31s 520ms/step - loss: 0.9830 - sparse_categorical_accuracy: 0.6855\n",
      "Epoch 2/10\n",
      "31/31 [==============================] - 16s 450ms/step - loss: 0.7247 - sparse_categorical_accuracy: 0.7641\n",
      "Epoch 3/10\n",
      "31/31 [==============================] - 17s 462ms/step - loss: 0.6864 - sparse_categorical_accuracy: 0.7794\n",
      "Epoch 4/10\n",
      "31/31 [==============================] - 16s 451ms/step - loss: 0.6936 - sparse_categorical_accuracy: 0.7719\n",
      "Epoch 5/10\n",
      "31/31 [==============================] - 16s 452ms/step - loss: 0.6505 - sparse_categorical_accuracy: 0.7956\n",
      "Epoch 6/10\n",
      "31/31 [==============================] - 16s 446ms/step - loss: 0.6467 - sparse_categorical_accuracy: 0.7901\n",
      "Epoch 7/10\n",
      "31/31 [==============================] - 16s 458ms/step - loss: 0.6129 - sparse_categorical_accuracy: 0.8016\n",
      "Epoch 8/10\n",
      "31/31 [==============================] - 16s 443ms/step - loss: 0.6406 - sparse_categorical_accuracy: 0.7911\n",
      "Epoch 9/10\n",
      "31/31 [==============================] - 16s 433ms/step - loss: 0.6560 - sparse_categorical_accuracy: 0.7862\n",
      "Epoch 10/10\n",
      "31/31 [==============================] - 16s 446ms/step - loss: 0.6147 - sparse_categorical_accuracy: 0.8032\n",
      "\n",
      "Finished, saving model to file:///home/mvonpohl/.local/share/delta/mlflow/1/bf8541ae88d94301a5906dfdf157a542/artifacts/final_model.savedmodel.\n",
      "Elapsed time =  186.9908163547516\n"
     ]
    }
   ],
   "source": [
    "!delta train --config l8_cloud_dataset.yaml --config l8_train_network.yaml l8_clouds.SavedModel 2>/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Examine Model Results\n",
    "\n",
    "The previous step produced a trained model. Now we can use the model to classify the images we set aside in the \"validate\" folder."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39fce69d-5227-4de6-b7be-85abbb301bb1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LC82290562014157LGN00_24_data : |XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX| 4 / 4\n",
      "Shadow              --- Precision:  71.66%    Recall:  18.84%        Pixels: 140931 / 1048576\n",
      "Shadow over Water   --- Precision:   0.00%    Recall:   0.00%        Pixels: 41893 / 1048576\n",
      "Water               --- Precision:  84.42%    Recall:  94.72%        Pixels: 259184 / 1048576\n",
      "Snow                --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 1048576\n",
      "Land                --- Precision:  57.91%    Recall:  99.38%        Pixels: 307181 / 1048576\n",
      "Cloud               --- Precision:  98.77%    Recall:  63.86%        Pixels: 299387 / 1048576\n",
      "Flooded             --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 1048576\n",
      " 73.29% Correct\n",
      "LC82210662014229LGN00_18_data : |XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX| 4 / 4\n",
      "Shadow              --- Precision:  99.59%    Recall:   8.21%        Pixels: 107635 / 1048576\n",
      "Shadow over Water   --- Precision:   0.00%    Recall:   0.00%        Pixels: 155 / 1048576\n",
      "Water               --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 1048576\n",
      "Snow                --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 1048576\n",
      "Land                --- Precision:  81.79%    Recall:  99.91%        Pixels: 794499 / 1048576\n",
      "Cloud               --- Precision:  98.55%    Recall:  46.42%        Pixels: 146287 / 1048576\n",
      "Flooded             --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 1048576\n",
      " 83.02% Correct\n",
      "Overall:\n",
      "Shadow              --- Precision:  77.06%    Recall:  14.24%        Pixels: 248566 / 2097152\n",
      "Shadow over Water   --- Precision:   0.00%    Recall:   0.00%        Pixels: 42048 / 2097152\n",
      "Water               --- Precision:  84.33%    Recall:  94.72%        Pixels: 259184 / 2097152\n",
      "Snow                --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 2097152\n",
      "Land                --- Precision:  73.39%    Recall:  99.76%        Pixels: 1101680 / 2097152\n",
      "Cloud               --- Precision:  98.71%    Recall:  58.14%        Pixels: 445674 / 2097152\n",
      "Flooded             --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 2097152\n",
      " 78.16% Correct\n",
      "Elapsed time =  2.800541877746582\n"
     ]
    }
   ],
   "source": [
    "!delta classify --config l8_cloud_dataset.yaml --image-dir ./validate --outdir ./no_overlap l8_clouds.SavedModel 2>/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a3c2ad-bc45-46e2-920e-fcea332f7187",
   "metadata": {},
   "source": [
    "### Validation Image\n",
    "The validation image we fed into the model.\n",
    "\n",
    "<img src='example_screenshots/Screen Shot 2021-07-14 at 1.35.36 PM.png'>\n",
    "\n",
    "### Validation Model Output\n",
    "The output from the model classifying the land cover in the above image.\n",
    "\n",
    "<img src='example_screenshots/Screen Shot 2021-07-14 at 1.36.41 PM.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557a357d-4b52-47c6-8412-1e22d9e10ae5",
   "metadata": {},
   "source": [
    "## Train Modified Model\n",
    "\n",
    "The previous model we trained classified all the land cover types in the landsat 8 dataset (water, snow, clouds, etc.). Now we're going to make a simple modification to the dataset configuration file and train a model that just classifies water in the satellite image.\n",
    "\n",
    "All we have to do is add one of DELTA's built in preprocessing functions. It will map all the of the classes except water to one class and set water as the other class.\n",
    "\n",
    "<a href='./l8_cloud_dataset_mod1.yaml' > l8_cloud_dataset_mod1.yaml </a><br />\n",
    "<a href='./l8_cloud_train_network_mod1.yaml' > l8_cloud_train_network_mod1.yaml </a>\n",
    "\n",
    "Excerpt from l8_cloud_dataset_mod1.yaml :\n",
    "```yaml\n",
    "# ______________\n",
    "# this mapping section tells DELTA to set all\n",
    "# the classes EXCEPT water to 0 and the water\n",
    "# claass to 2\n",
    "# ______________\n",
    "    preprocess:\n",
    "      - substitute:\n",
    "          mapping:\n",
    "            - 0\n",
    "            - 0\n",
    "            - 2\n",
    "            - 0\n",
    "            - 0\n",
    "            - 0\n",
    "            - 0\n",
    "  classes:\n",
    "    - 0:\n",
    "        name: Shadow\n",
    "        color: 0x000000\n",
    "    - 1:\n",
    "        name: Shadow over Water\n",
    "        color: 0x000080\n",
    "    - 2:\n",
    "        name: Water\n",
    "        color: 0x0000FF\n",
    "    - 3:\n",
    "        name: Snow\n",
    "        color: 0x00FFFF\n",
    "    - 4:\n",
    "        name: Land\n",
    "        color: 0x808080\n",
    "    - 5:\n",
    "        name: Cloud\n",
    "        color: 0xFFFFFF\n",
    "    - 6:\n",
    "        name: Flooded\n",
    "        color: 0x808000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ed262ec-c77f-4d76-a35b-2deed10b6431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 31s 505ms/step - loss: 0.5149 - sparse_categorical_accuracy: 0.8845\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 16s 459ms/step - loss: 0.1606 - sparse_categorical_accuracy: 0.9453\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 16s 450ms/step - loss: 0.1455 - sparse_categorical_accuracy: 0.9429\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 16s 441ms/step - loss: 0.1311 - sparse_categorical_accuracy: 0.9501\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 17s 458ms/step - loss: 0.1471 - sparse_categorical_accuracy: 0.9440\n",
      "\n",
      "Finished, saving model to file:///home/mvonpohl/.local/share/delta/mlflow/1/66114b61efaf4bde871df044bf9b1dbc/artifacts/final_model.savedmodel.\n",
      "Elapsed time =  105.85115361213684\n"
     ]
    }
   ],
   "source": [
    "!delta train --config l8_cloud_dataset_mod1.yaml --config l8_cloud_train_network_mod1.yaml l8_clouds_mod1.SavedModel 2>/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Examine Model Results\n",
    "\n",
    "Now we can examine the new model by classifying the images we set aside in the \"validate\" folder."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04d43b75-711b-4e94-af68-8b407db452aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LC82290562014157LGN00_24_data : |XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX| 9 / 9\n",
      "Shadow              --- Precision:  98.98%    Recall:  95.22%        Pixels: 1830837 / 2167040\n",
      "Shadow over Water   --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 2167040\n",
      "Water               --- Precision:  78.44%    Recall:  94.68%        Pixels: 336203 / 2167040\n",
      "Snow                --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 2167040\n",
      "Land                --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 2167040\n",
      "Cloud               --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 2167040\n",
      "Flooded             --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 2167040\n",
      " 95.14% Correct\n",
      "LC82210662014229LGN00_18_data : |XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX| 9 / 9\n",
      "Shadow              --- Precision: 100.00%    Recall: 100.00%        Pixels: 2167040 / 2167040\n",
      "Shadow over Water   --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 2167040\n",
      "Water               --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 2167040\n",
      "Snow                --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 2167040\n",
      "Land                --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 2167040\n",
      "Cloud               --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 2167040\n",
      "Flooded             --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 2167040\n",
      "100.00% Correct\n",
      "Overall:\n",
      "Shadow              --- Precision:  99.54%    Recall:  97.81%        Pixels: 3997877 / 4334080\n",
      "Shadow over Water   --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 4334080\n",
      "Water               --- Precision:  78.44%    Recall:  94.68%        Pixels: 336203 / 4334080\n",
      "Snow                --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 4334080\n",
      "Land                --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 4334080\n",
      "Cloud               --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 4334080\n",
      "Flooded             --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 4334080\n",
      " 97.57% Correct\n",
      "Elapsed time =  4.004173278808594\n"
     ]
    }
   ],
   "source": [
    "!delta classify --config l8_cloud_dataset-mod1.yaml --image-dir ./validate --outdir ./mod1_overlap_32 --overlap 32 l8_clouds_mod1.SavedModel 2>/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9ccfee-eb04-4681-8bc3-4a152780f028",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Validation Image\n",
    "The validation image we fed into the model.\n",
    "\n",
    "<img src='example_screenshots/Screen Shot 2021-07-14 at 1.35.36 PM.png'>\n",
    "\n",
    "### Validation Model Output\n",
    "The output from the model classifying water coverage in the above image.\n",
    "\n",
    "<img src='example_screenshots/Screen Shot 2021-07-14 at 2.17.03 PM.png'>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}