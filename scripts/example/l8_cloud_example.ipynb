{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e7f5958",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Landsat 8 Classification Example\n",
    "\n",
    "This example will walk you through an example of using DELTA to train a simple example model. You can use what you learn here to use DELTA on your own datasets and with your own model architectures.\n",
    "In this example you will:\n",
    "- Download a dataset of images and labels\n",
    "- Train a simple model using example configuration files\n",
    "- Examine results of the trained model\n",
    "- Make some changes to the configuration files and train a modified model\n",
    "- Examine the results of the modified model\n",
    "\n",
    "## Downloading and Extracting Dataset\n",
    "\n",
    "The dataset includes satellite images along with classification labels for different types of land cover (water, cloud, snow, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fda33b66-8759-4600-96af-10328dfe09a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset.\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1483M  100 1483M    0     0  4333k      0  0:05:50  0:05:50 --:--:-- 6467k  0  0:03:21  0:00:34  0:02:47 6195kk 0  6080k      0  0:04:09  0:00:44  0:03:25 1240k164k      0  0:06:04  0:01:12  0:04:52 1861k2M    0     0  4104k      0  0:06:10  0:01:20  0:04:50 3942k 0  0:05:48  0:01:33  0:04:15 6833k46  0:03:54 5871k      0  0:05:22  0:01:56  0:03:26 7779k0  0:05:16  0:02:50  0:02:26 4334k      0  0:05:38  0:03:44  0:01:54  870k0  0:05:42  0:03:47  0:01:55  586k  0:03:48  0:01:55  521k0  0:00:40 7809k05:39  0:00:16 4483k\n"
     ]
    }
   ],
   "source": [
    "!echo \"Downloading dataset.\"\n",
    "!curl -O https://landsat.usgs.gov/cloud-validation/sparcs/l8cloudmasks.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ba710e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we're extracting the dataset and organizing the images into folders.\n",
    "We are:\n",
    "- setting aside two images in a folder called \"validate\" to test our model later\n",
    "- moving the satellite images into a folder called \"train\"\n",
    "- moving the classification labels into a folder called \"labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f7c8cdb-0213-4382-8746-4dead4ae57f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset.\n",
      "mkdir: labels: File exists\n"
     ]
    }
   ],
   "source": [
    "!echo \"Extracting dataset.\"\n",
    "!unzip -q l8cloudmasks.zip\n",
    "!mkdir validate\n",
    "!mv sending/LC82290562014157LGN00_24_data.tif sending/LC82210662014229LGN00_18_data.tif validate/\n",
    "!mkdir train\n",
    "!mv sending/*_data.tif train/\n",
    "!mkdir labels\n",
    "!mv sending/*_mask.png labels/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e6913ec-6e08-483e-989d-7fc7d0f6dfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34mexample_screenshots\u001B[m\u001B[m            l8_cloud_train_parameters.yaml\n",
      "\u001B[31ml8_cloud.sh\u001B[m\u001B[m                    l8cloudmasks.zip\n",
      "l8_cloud_dataset.yaml          \u001B[34mlabels\u001B[m\u001B[m\n",
      "l8_cloud_dataset_water.yaml    \u001B[34msending\u001B[m\u001B[m\n",
      "l8_cloud_example.ipynb         \u001B[34mtrain\u001B[m\u001B[m\n",
      "l8_cloud_train_network.yaml    \u001B[34mvalidate\u001B[m\u001B[m\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf80050d-ca27-4e31-8d5b-a76f00ed6b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LC80010812013365LGN00_18_data.tif\n",
      "LC80020622013244LGN00_32_data.tif\n",
      "LC80050152014172LGN00_12_data.tif\n",
      "LC80050562014076LGN00_33_data.tif\n",
      "LC80150242014146LGN00_23_data.tif\n",
      "LC80190352014078LGN01_26_data.tif\n",
      "LC80200462014213LGN00_11_data.tif\n",
      "LC80250402013245LGN00_45_data.tif\n",
      "LC80250482014072LGN00_18_data.tif\n",
      "LC80310432013207LGN00_11_data.tif\n"
     ]
    }
   ],
   "source": [
    "!ls train/ | head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed0d005-6a9e-41a1-9582-18cbfc21084e",
   "metadata": {},
   "source": [
    "### Example Satellite Image\n",
    "<img src='example_screenshots/Screen Shot 2021-07-13 at 6.57.11 PM.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79a00a8c-7b1f-4609-9c7e-3947f4a14a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LC80010812013365LGN00_18_mask.png\n",
      "LC80020622013244LGN00_32_mask.png\n",
      "LC80050152014172LGN00_12_mask.png\n",
      "LC80050562014076LGN00_33_mask.png\n",
      "LC80150242014146LGN00_23_mask.png\n",
      "LC80190352014078LGN01_26_mask.png\n",
      "LC80200462014213LGN00_11_mask.png\n",
      "LC80250402013245LGN00_45_mask.png\n",
      "LC80250482014072LGN00_18_mask.png\n",
      "LC80310432013207LGN00_11_mask.png\n"
     ]
    }
   ],
   "source": [
    "!ls labels | head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e792438d-8a1a-4323-b24d-fce7488b65fd",
   "metadata": {},
   "source": [
    "### Example Label Image\n",
    "\n",
    "The different colors represent different land cover classifications.\n",
    "\n",
    "<img src='labels/LC80010812013365LGN00_18_mask.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09da9259-107c-4dc4-a284-a1fc780ab30f",
   "metadata": {},
   "source": [
    "## Training a Model\n",
    "\n",
    "We'll use the following configuration files which specify a dataset to use (l8_cloud_dataset.yaml), a network architecture to train (l8_cloud_train_network.yaml), and the parameters to train with (l8_cloud_train_parameters.yaml).\n",
    "\n",
    "### Configuration YAMLs\n",
    "\n",
    "<a href='./l8_cloud_dataset.yaml' > l8_cloud_dataset.yaml </a><br />\n",
    "<a href='./l8_cloud_train_network.yaml' > l8_cloud_train_network.yaml </a><br />\n",
    "<a href='./l8_cloud_train_parameters.yaml' > l8_cloud_train_parameters.yaml </a>\n",
    "\n",
    "<a href='../../../delta/config/README.md' > Detailed Config Documentation </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8881b152-6c50-4ec2-b7a7-7d35db3cbb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-10 11:09:58.657216: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-10 11:09:58.686678: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcdb2e457a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-11-10 11:09:58.686712: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From /Users/mvonpohl/miniconda3/envs/delta/lib/python3.6/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "31/31 [==============================] - 372s 12s/step - loss: 0.9725 - sparse_categorical_accuracy: 0.6823\n",
      "Epoch 2/10\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.6424 - sparse_categorical_accuracy: 0.7887WARNING:tensorflow:From /Users/mvonpohl/miniconda3/envs/delta/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "2021-11-10 11:21:31.944887: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:tensorflow:From /Users/mvonpohl/miniconda3/envs/delta/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "31/31 [==============================] - 287s 9s/step - loss: 0.6424 - sparse_categorical_accuracy: 0.7887\n",
      "Epoch 3/10\n",
      "31/31 [==============================] - 285s 9s/step - loss: 0.6106 - sparse_categorical_accuracy: 0.8053\n",
      "Epoch 4/10\n",
      "31/31 [==============================] - 298s 10s/step - loss: 0.5645 - sparse_categorical_accuracy: 0.8141\n",
      "Epoch 5/10\n",
      "31/31 [==============================] - 390s 13s/step - loss: 0.5538 - sparse_categorical_accuracy: 0.8184\n",
      "Epoch 6/10\n",
      "31/31 [==============================] - 286s 9s/step - loss: 0.5593 - sparse_categorical_accuracy: 0.8221\n",
      "Epoch 7/10\n",
      "31/31 [==============================] - 264s 9s/step - loss: 0.5814 - sparse_categorical_accuracy: 0.8223\n",
      "Epoch 8/10\n",
      "31/31 [==============================] - 268s 9s/step - loss: 0.5649 - sparse_categorical_accuracy: 0.8225\n",
      "Epoch 9/10\n",
      " 7/31 [=====>........................] - ETA: 5:50 - loss: 0.5821 - sparse_categorical_accuracy: 0.8094^C\n"
     ]
    }
   ],
   "source": [
    "!delta train --config l8_cloud_dataset.yaml --config l8_cloud_train_network.yaml --config l8_cloud_train_parameters.yaml l8_clouds.SavedModel 2>/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d217e4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Examine Model Results\n",
    "\n",
    "The previous step produced a trained model. Now we can use the model to classify the images we set aside in the \"validate\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39fce69d-5227-4de6-b7be-85abbb301bb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LC82290562014157LGN00_24_data : |XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX| 4 / 4\n",
      "Shadow              --- Precision:  71.66%    Recall:  18.84%        Pixels: 140931 / 1048576\n",
      "Shadow over Water   --- Precision:   0.00%    Recall:   0.00%        Pixels: 41893 / 1048576\n",
      "Water               --- Precision:  84.42%    Recall:  94.72%        Pixels: 259184 / 1048576\n",
      "Snow                --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 1048576\n",
      "Land                --- Precision:  57.91%    Recall:  99.38%        Pixels: 307181 / 1048576\n",
      "Cloud               --- Precision:  98.77%    Recall:  63.86%        Pixels: 299387 / 1048576\n",
      "Flooded             --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 1048576\n",
      " 73.29% Correct\n",
      "LC82210662014229LGN00_18_data : |XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX| 4 / 4\n",
      "Shadow              --- Precision:  99.59%    Recall:   8.21%        Pixels: 107635 / 1048576\n",
      "Shadow over Water   --- Precision:   0.00%    Recall:   0.00%        Pixels: 155 / 1048576\n",
      "Water               --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 1048576\n",
      "Snow                --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 1048576\n",
      "Land                --- Precision:  81.79%    Recall:  99.91%        Pixels: 794499 / 1048576\n",
      "Cloud               --- Precision:  98.55%    Recall:  46.42%        Pixels: 146287 / 1048576\n",
      "Flooded             --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 1048576\n",
      " 83.02% Correct\n",
      "Overall:\n",
      "Shadow              --- Precision:  77.06%    Recall:  14.24%        Pixels: 248566 / 2097152\n",
      "Shadow over Water   --- Precision:   0.00%    Recall:   0.00%        Pixels: 42048 / 2097152\n",
      "Water               --- Precision:  84.33%    Recall:  94.72%        Pixels: 259184 / 2097152\n",
      "Snow                --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 2097152\n",
      "Land                --- Precision:  73.39%    Recall:  99.76%        Pixels: 1101680 / 2097152\n",
      "Cloud               --- Precision:  98.71%    Recall:  58.14%        Pixels: 445674 / 2097152\n",
      "Flooded             --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 2097152\n",
      " 78.16% Correct\n",
      "Elapsed time =  2.800541877746582\n"
     ]
    }
   ],
   "source": [
    "!delta classify --config l8_cloud_dataset.yaml --image-dir ./validate --outdir ./model_output --overlap 32 l8_clouds.SavedModel 2>/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a3c2ad-bc45-46e2-920e-fcea332f7187",
   "metadata": {},
   "source": [
    "### Validation Image\n",
    "The validation image we fed into the model.\n",
    "\n",
    "<img src='example_screenshots/Screen Shot 2021-07-14 at 1.35.36 PM.png'>\n",
    "\n",
    "### Validation Model Output\n",
    "The output from the model classifying the land cover in the above image.\n",
    "\n",
    "<img src='example_screenshots/Screen Shot 2021-07-14 at 1.36.41 PM.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557a357d-4b52-47c6-8412-1e22d9e10ae5",
   "metadata": {},
   "source": [
    "## Train Modified Model\n",
    "\n",
    "The previous model we trained classified all the land cover types in the landsat 8 dataset (water, snow, clouds, etc.). Now we're going to make a simple modification to the dataset configuration file and train a model that just classifies water in the satellite image.\n",
    "\n",
    "All we have to do is add one of DELTA's built in preprocessing functions. It will map all the of the classes except water to one class and set water as the other class.\n",
    "\n",
    "<a href='./l8_cloud_dataset_water.yaml' > l8_cloud_dataset_water.yaml </a><br />\n",
    "\n",
    "Excerpt from l8_cloud_dataset_water.yaml :\n",
    "```yaml\n",
    "# ______________\n",
    "# this mapping section tells DELTA to set all\n",
    "# the classes EXCEPT water to 0 and the water\n",
    "# claass to 2\n",
    "# ______________\n",
    "    preprocess:\n",
    "      - substitute:\n",
    "          mapping:\n",
    "            - 0\n",
    "            - 0\n",
    "            - 2\n",
    "            - 0\n",
    "            - 0\n",
    "            - 0\n",
    "            - 0\n",
    "  classes:\n",
    "    - 0:\n",
    "        name: Shadow\n",
    "        color: 0x000000\n",
    "    - 1:\n",
    "        name: Shadow over Water\n",
    "        color: 0x000080\n",
    "    - 2:\n",
    "        name: Water\n",
    "        color: 0x0000FF\n",
    "    - 3:\n",
    "        name: Snow\n",
    "        color: 0x00FFFF\n",
    "    - 4:\n",
    "        name: Land\n",
    "        color: 0x808080\n",
    "    - 5:\n",
    "        name: Cloud\n",
    "        color: 0xFFFFFF\n",
    "    - 6:\n",
    "        name: Flooded\n",
    "        color: 0x808000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ed262ec-c77f-4d76-a35b-2deed10b6431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 31s 505ms/step - loss: 0.5149 - sparse_categorical_accuracy: 0.8845\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 16s 459ms/step - loss: 0.1606 - sparse_categorical_accuracy: 0.9453\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 16s 450ms/step - loss: 0.1455 - sparse_categorical_accuracy: 0.9429\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 16s 441ms/step - loss: 0.1311 - sparse_categorical_accuracy: 0.9501\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 17s 458ms/step - loss: 0.1471 - sparse_categorical_accuracy: 0.9440\n",
      "\n",
      "Finished, saving model to file:///home/mvonpohl/.local/share/delta/mlflow/1/66114b61efaf4bde871df044bf9b1dbc/artifacts/final_model.savedmodel.\n",
      "Elapsed time =  105.85115361213684\n"
     ]
    }
   ],
   "source": [
    "!delta train --config l8_cloud_dataset_water.yaml --config l8_cloud_train_network.yaml --config l8_cloud_train_parameters.yaml l8_clouds_water.SavedModel 2>/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50b47b0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Examine Model Results\n",
    "\n",
    "Now we can examine the new model by classifying the images we set aside in the \"validate\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04d43b75-711b-4e94-af68-8b407db452aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LC82290562014157LGN00_24_data : |XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX| 9 / 9\n",
      "Shadow              --- Precision:  98.98%    Recall:  95.22%        Pixels: 1830837 / 2167040\n",
      "Shadow over Water   --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 2167040\n",
      "Water               --- Precision:  78.44%    Recall:  94.68%        Pixels: 336203 / 2167040\n",
      "Snow                --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 2167040\n",
      "Land                --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 2167040\n",
      "Cloud               --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 2167040\n",
      "Flooded             --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 2167040\n",
      " 95.14% Correct\n",
      "LC82210662014229LGN00_18_data : |XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX| 9 / 9\n",
      "Shadow              --- Precision: 100.00%    Recall: 100.00%        Pixels: 2167040 / 2167040\n",
      "Shadow over Water   --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 2167040\n",
      "Water               --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 2167040\n",
      "Snow                --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 2167040\n",
      "Land                --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 2167040\n",
      "Cloud               --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 2167040\n",
      "Flooded             --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 2167040\n",
      "100.00% Correct\n",
      "Overall:\n",
      "Shadow              --- Precision:  99.54%    Recall:  97.81%        Pixels: 3997877 / 4334080\n",
      "Shadow over Water   --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 4334080\n",
      "Water               --- Precision:  78.44%    Recall:  94.68%        Pixels: 336203 / 4334080\n",
      "Snow                --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 4334080\n",
      "Land                --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 4334080\n",
      "Cloud               --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 4334080\n",
      "Flooded             --- Precision:   0.00%    Recall:   0.00%        Pixels: 0 / 4334080\n",
      " 97.57% Correct\n",
      "Elapsed time =  4.004173278808594\n"
     ]
    }
   ],
   "source": [
    "!delta classify --config l8_cloud_dataset_water.yaml --image-dir ./validate --outdir ./model_output_water --overlap 32 l8_clouds_water.SavedModel 2>/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9ccfee-eb04-4681-8bc3-4a152780f028",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Validation Image\n",
    "The validation image we fed into the model.\n",
    "\n",
    "<img src='example_screenshots/Screen Shot 2021-07-14 at 1.35.36 PM.png'>\n",
    "\n",
    "### Validation Model Output\n",
    "The output from the model classifying water coverage in the above image.\n",
    "\n",
    "<img src='example_screenshots/Screen Shot 2021-07-14 at 2.17.03 PM.png'>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}